# Atlas —— 基于 RAG 的本地知识库智能问答系统

## 一、项目背景与研究意义

### 1.1 研究背景

随着大语言模型（Large Language Model, LLM）技术的快速发展，以 ChatGPT 为代表的通用对话系统展现了强大的自然语言理解与生成能力。然而，通用大模型存在以下固有局限：

1. **知识时效性问题**：模型的知识截止于训练数据的时间点，无法获取最新信息。
2. **领域知识缺失**：对于特定行业或组织的专有知识（如企业内部文档、学术论文、法规条文等），通用模型缺乏覆盖。
3. **幻觉问题（Hallucination）**：模型在缺乏相关知识时，可能生成看似合理但实际错误的回答。
4. **数据隐私顾虑**：将敏感文档上传到云端大模型服务存在数据泄露风险，不符合部分行业的合规要求。

检索增强生成（Retrieval-Augmented Generation, RAG）技术的出现为上述问题提供了有效的解决方案。RAG 通过在生成阶段引入外部知识检索环节，使大模型能够基于真实文档内容进行回答，显著提升了回答的准确性和可追溯性。

### 1.2 研究意义

本项目设计并实现了一个**完全本地化部署**的知识库智能问答系统 Atlas，具有以下研究意义：

- **理论意义**：探索 RAG 技术在本地化场景下的工程实现方案，研究文档解析、文本分块、向量检索、上下文注入等关键环节的最优实践。
- **实际意义**：为个人用户和中小型组织提供一个零成本、零依赖云端 API、保护数据隐私的本地知识库问答工具，可应用于文档助手、智能客服、研究辅助等场景。

---

## 二、系统需求分析

### 2.1 功能需求

| 编号 | 功能模块 | 功能描述 |
|------|---------|---------|
| F1 | 知识库管理 | 创建、编辑、删除知识库，支持多知识库并存 |
| F2 | 文档管理 | 上传文档（PDF/DOCX/TXT/MD），自动解析、分块、向量化索引 |
| F3 | 智能问答 | 基于知识库内容的 RAG 问答，支持流式输出 |
| F4 | 通用对话 | 不依赖知识库的通用聊天能力 |
| F5 | 对话管理 | 多轮对话历史记录、对话列表管理 |
| F6 | 模型切换 | 支持在多个本地模型间动态切换 |
| F7 | 文档预览 | 查看文档分片内容，了解知识被如何切分 |
| F8 | 多知识库检索 | 单次对话可同时关联多个知识库进行联合检索 |

### 2.2 非功能需求

| 编号 | 需求类型 | 描述 |
|------|---------|------|
| NF1 | 隐私安全 | 全部数据存储在本地，模型推理在本地完成，不依赖任何云端服务 |
| NF2 | 响应性能 | 采用流式输出（SSE），首字符响应延迟低，用户体验流畅 |
| NF3 | 一键部署 | 前后端打包为单一 macOS .dmg 安装包，用户双击即可使用 |
| NF4 | 可扩展性 | 模块化架构，文档解析器、向量数据库、LLM 均可替换 |

---

## 三、系统总体设计

### 3.1 系统架构

本系统采用**前后端分离 + 本地模型推理**的三层架构：

```
┌─────────────────────────────────────────────────────┐
│                   表现层（Presentation）               │
│   Electron 桌面应用 + React UI + Ant Design 组件库     │
│   ┌──────────┐  ┌──────────┐  ┌─────────────────┐   │
│   │ 侧边栏    │  │ 对话面板  │  │ 知识库文档管理   │   │
│   └──────────┘  └──────────┘  └─────────────────┘   │
│         │              │              │               │
│         └──────────────┼──────────────┘               │
│                        │ HTTP / SSE                   │
├────────────────────────┼────────────────────────────┤
│                   业务层（Business）                    │
│              Python FastAPI REST API                  │
│   ┌──────────┐  ┌──────────┐  ┌─────────────────┐   │
│   │ 对话 API  │  │ 文档 API  │  │ 知识库 API      │   │
│   └────┬─────┘  └────┬─────┘  └───────┬─────────┘   │
│        │              │                │              │
│   ┌────┴──────────────┴────────────────┴──────────┐  │
│   │            RAG 编排服务（核心引擎）              │  │
│   │  检索(Retrieve) → 上下文构建 → 生成(Generate)   │  │
│   └────┬──────────────┬────────────────┬──────────┘  │
│        │              │                │              │
├────────┼──────────────┼────────────────┼────────────┤
│        │         数据层（Data）          │              │
│   ┌────┴─────┐  ┌─────┴──────┐  ┌─────┴──────────┐  │
│   │ Ollama   │  │ ChromaDB   │  │ SQLite         │  │
│   │ 本地LLM  │  │ 向量数据库  │  │ 关系数据库      │  │
│   └──────────┘  └────────────┘  └────────────────┘  │
└─────────────────────────────────────────────────────┘
```

### 3.2 技术选型

| 层次 | 技术 | 版本 | 选型理由 |
|------|------|------|---------|
| **前端框架** | React | 18.2 | 组件化开发，生态成熟，适合构建复杂交互界面 |
| **UI 组件库** | Ant Design (antd) | 6.3 | 企业级 UI 组件库，提供丰富的开箱即用组件 |
| **AI 交互组件** | @ant-design/x | 2.2 | 专为 AI 对话场景设计的组件（Bubble、Think、Sender 等） |
| **状态管理** | Zustand | 4.5 | 轻量级状态管理，API 简洁，无模板代码 |
| **桌面框架** | Electron | 28.0 | 跨平台桌面应用框架，复用 Web 技术栈 |
| **应用打包** | PyInstaller | ≥6.0 | 将 Python 后端打包为独立可执行文件，嵌入 Electron 应用 |
| **构建工具** | Vite | 5.0 | 基于 ESM 的极速开发服务器和构建工具 |
| **后端框架** | FastAPI | ≥0.109 | 高性能异步 Python Web 框架，自动生成 API 文档 |
| **LLM 推理** | Ollama | ≥0.4 | 本地大模型运行平台，支持多种开源模型 |
| **对话模型** | Qwen3:14b | - | 通义千问 14B 参数模型，中文能力优秀 |
| **嵌入模型** | Qwen3-embedding:4b | - | 通义千问嵌入模型，中文语义表示能力强 |
| **向量数据库** | ChromaDB | ≥0.4.22 | 轻量级嵌入式向量数据库，支持持久化和相似度检索 |
| **关系数据库** | SQLite + aiosqlite | ≥2.0 | 零配置嵌入式数据库，配合异步驱动实现非阻塞访问 |
| **ORM** | SQLAlchemy | ≥2.0 | Python 主流 ORM，支持异步查询 |
| **PDF 解析** | PyMuPDF | ≥1.23 | 高性能 PDF 解析库，支持文本提取 |
| **Word 解析** | python-docx | ≥1.1 | Word 文档段落文本提取 |
| **文本分块** | LangChain Text Splitters | ≥0.0.1 | 递归字符分割器，支持自定义分隔符 |

---

## 四、系统详细设计

### 4.1 RAG 核心流程

RAG 是本系统的核心算法，其完整流程如下：

```
用户提问
  │
  ▼
┌──────────────────┐
│  1. 问题向量化     │  调用 Ollama Embedding 模型
│  Query → Vector   │  将自然语言问题转换为高维向量
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│  2. 语义检索       │  在 ChromaDB 中进行余弦相似度检索
│  Vector → Top-K   │  返回最相关的 K 个文档片段（默认 K=5）
│  Chunks           │  支持按文档 ID 过滤检索范围
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│  3. 上下文构建     │  将检索到的片段格式化为结构化上下文
│  Chunks → Context │  包含来源标注（文档 ID、片段编号）
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│  4. 提示词组装     │  将上下文注入到系统提示词模板中
│  Context → Prompt │  与对话历史记录一起构建完整的消息数组
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│  5. 流式生成       │  调用 Ollama 对话模型（Qwen3:14b）
│  Prompt → Stream  │  通过 SSE 逐 token 推送到前端
│  Response         │  支持分离「思考过程」和「回答内容」
└──────────────────┘
```

### 4.2 文档索引流程

文档从上传到可被检索，经历以下处理管线：

```
用户上传文件
  │
  ▼
┌──────────────────┐
│ 1. 文件保存        │  保存到本地 data/uploads/ 目录
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│ 2. 文档解析        │  根据文件类型选择解析器（策略模式）
│  PDF  → PyMuPDF   │  PDF:     逐页提取文本
│  DOCX → python-   │  DOCX:    提取段落文本
│         docx      │  TXT/MD:  自动检测编码后读取
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│ 3. 文本分块        │  RecursiveCharacterTextSplitter
│  chunk_size=600   │  按语义边界递归分割
│  overlap=100      │  相邻片段保留 100 字符重叠
│                   │  分隔符优先级：段落 > 句子 > 逗号 > 字符
│                   │  针对中英文混合内容优化
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│ 4. 向量化          │  调用 Ollama Embedding 模型
│  Text → Vector    │  批量将所有片段转换为向量表示
│                   │  自动按 50 个一批分批发送，避免大文件超时
└────────┬─────────┘
         │
         ▼
┌──────────────────┐
│ 5. 持久化存储      │  向量 + 原文 + 元数据 → ChromaDB
│                   │  文档元信息 → SQLite
└──────────────────┘
```

### 4.3 文本分块策略

文本分块是 RAG 系统中影响检索质量的关键环节。本系统采用递归字符分割策略，针对中英文混合文档优化了分隔符优先级：

| 优先级 | 分隔符 | 说明 |
|-------|--------|------|
| 1 | `\n\n` | 段落分隔（最优分割点） |
| 2 | `\n` | 换行 |
| 3 | `。！？；` | 中文句末标点 |
| 4 | `. ! ? ;` | 英文句末标点 |
| 5 | `，` `, ` | 逗号 |
| 6 | 空格 | 词级分割 |
| 7 | 空字符串 | 字符级兜底 |

分块参数设计依据：
- **chunk_size = 600 字符**：平衡语义完整性和检索精度。过大导致检索不精确，过小导致语义断裂。
- **chunk_overlap = 100 字符**：相邻片段保留重叠区域，确保跨分块边界的信息不被丢失。

### 4.4 数据库设计

#### 4.4.1 关系数据库（SQLite）—— E-R 图

```
┌──────────────────┐        ┌──────────────────┐
│  KnowledgeBase   │        │   Conversation   │
│──────────────────│        │──────────────────│
│ PK  id (UUID)    │        │ PK  id (UUID)    │
│     name         │        │     title        │
│     description  │        │     created_at   │
│     created_at   │        │     updated_at   │
│     updated_at   │        └────────┬─────────┘
└────────┬─────────┘                 │
         │ 1:N                       │ 1:N
         │                           │
┌────────┴─────────┐        ┌────────┴─────────┐
│    Document      │        │     Message      │
│──────────────────│        │──────────────────│
│ PK  id (UUID)    │        │ PK  id (UUID)    │
│ FK  kb_id        │        │ FK  conv_id      │
│     filename     │        │     role         │
│     file_type    │        │     content      │
│     file_size    │        │     created_at   │
│     chunk_count  │        └──────────────────┘
│     created_at   │
└──────────────────┘
```

#### 4.4.2 向量数据库（ChromaDB）

| 字段 | 类型 | 说明 |
|------|------|------|
| id | string | 片段唯一标识（格式：`{document_id}_{chunk_index}`） |
| embedding | float[] | 文本向量表示 |
| document | string | 片段原文内容 |
| metadata | dict | 元数据（document_id, filename, chunk_index, total_chunks） |

检索方式：余弦相似度（cosine similarity），返回 Top-K 最相似片段。

### 4.5 前端界面设计

系统界面采用经典的「侧边栏 + 主内容区」双栏布局：

```
┌──────────┬──────────────────────────────────┐
│          │       模型选择下拉菜单             │
│  搜索框   ├──────────────────────────────────┤
│          │                                   │
│ ┌──────┐ │         对话消息气泡区域            │
│ │对话1  │ │                                   │
│ │对话2  │ │   [用户消息]          蓝色气泡右对齐│
│ │对话3  │ │   [思考过程折叠面板]               │
│ │ ...  │ │   [助手回答] Markdown 渲染 左对齐  │
│ └──────┘ │   [复制按钮]                       │
│          │                                   │
│          ├──────────────────────────────────┤
│ ┌──────┐ │   [已选知识库标签]                  │
│ │ 对话  │ │   ┌─────────────────────────────┐ │
│ │知识库 │ │   │ 📚 消息输入框          发送  │ │
│ └──────┘ │   └─────────────────────────────┘ │
└──────────┴──────────────────────────────────┘
  侧边栏                 主内容区
```

侧边栏支持「对话」和「知识库」两种模式切换：
- **对话模式**：展示对话历史列表，按时间分组（今天/昨天/7天内/30天内/更早）
- **知识库模式**：展示知识库列表，支持勾选（用于对话检索范围）和点击（查看文档管理）

### 4.6 前后端通信设计

| 通信方式 | 应用场景 | 说明 |
|---------|---------|------|
| REST API (JSON) | CRUD 操作 | 知识库/文档/对话的增删改查 |
| SSE (Server-Sent Events) | 流式对话 | 模型生成过程实时推送到前端 |
| multipart/form-data | 文件上传 | 文档上传 |

SSE 流式通信的数据格式：
```
data: {"content": "回答片段", "reasoning": "思考过程片段", "done": false}\n\n
data: {"content": "",         "reasoning": "",             "done": true}\n\n
```

---

## 五、系统核心模块实现

### 5.1 后端模块划分

```
backend/app/
├── main.py              # FastAPI 应用入口（生命周期管理、中间件、路由注册）
├── config.py            # 全局配置（路径、模型、RAG 参数，支持 .env 和环境变量覆盖，打包模式自动切换数据目录）
├── api/                 # API 路由层
│   ├── chat.py          # 对话接口（SSE 流式响应、对话 CRUD）
│   ├── documents.py     # 文档接口（上传索引、查询、删除）
│   ├── knowledge_bases.py  # 知识库接口（CRUD、级联删除）
│   └── history.py       # 历史消息查询接口
├── core/                # 核心业务逻辑层
│   ├── rag.py           # RAG 编排服务（检索 + 上下文构建 + 生成）
│   ├── vectorstore.py   # ChromaDB 向量存储封装（增删查）
│   ├── ollama.py        # Ollama 模型服务封装（对话 + 向量化）
│   ├── parser.py        # 多格式文档解析（策略模式）
│   └── chunker.py       # 文本分块（递归字符分割）
├── models/              # ORM 数据模型
│   └── models.py        # KnowledgeBase, Document, Conversation, Message
└── db/                  # 数据库访问层
    ├── database.py      # SQLAlchemy 异步引擎和会话管理
    └── crud.py          # CRUD 操作封装
```

### 5.2 前端模块划分

```
frontend/src/
├── main/index.js              # Electron 主进程（窗口管理、后端进程生命周期）
├── preload/preload.js         # 预加载脚本（安全桥接、后端端口传递）
└── renderer/                  # React 渲染进程
    ├── App.tsx                # 根组件（布局和视图切换）
    ├── components/
    │   ├── ChatPanel.tsx      # 对话面板（消息收发、流式渲染）
    │   ├── Sidebar.tsx        # 侧边栏（对话列表 / 知识库列表）
    │   └── KnowledgeBaseView.tsx  # 知识库文档管理（上传/预览/删除）
    ├── services/
    │   └── api.ts             # API 服务层（HTTP 请求 + SSE 流式解析）
    ├── stores/
    │   ├── conversationStore.ts  # 对话状态管理（Zustand）
    │   └── knowledgeBaseStore.ts # 知识库状态管理（Zustand）
    └── styles/
        └── global.css         # 全局样式
```

### 5.3 设计模式应用

| 设计模式 | 应用位置 | 说明 |
|---------|---------|------|
| **策略模式** | 文档解析器 (parser.py) | BaseParser 定义接口，PDFParser/DocxParser/TextParser 各自实现，DocumentParser 统一调度 |
| **单例模式** | 核心服务实例 | rag_service、vector_store、ollama_service 均为全局单例 |
| **观察者模式** | SSE 流式通信 | 后端推送事件，前端注册回调处理 |
| **依赖注入** | FastAPI 路由 | 通过 Depends(get_session) 注入数据库会话 |
| **状态管理模式** | Zustand Store | 集中管理前端应用状态，组件通过 Hook 订阅 |

---

## 六、系统特色与创新点

### 6.1 完全本地化部署

系统全部组件运行在用户本机，不依赖任何云端服务：
- **模型推理**：通过 Ollama 在本地运行开源大模型
- **向量检索**：ChromaDB 嵌入式向量数据库
- **数据存储**：SQLite 嵌入式关系数据库
- **文件存储**：本地文件系统

这确保了用户数据的完全隐私，适用于对数据安全有严格要求的场景。

### 6.2 双模式智能切换

系统根据用户是否选择知识库，自动在两种模式间切换：
- **RAG 模式**：选择了知识库时，先检索再生成，回答基于文档内容
- **通用对话模式**：未选择知识库时，直接与大模型对话

用户无需手动切换，系统根据上下文自动选择最合适的模式。

### 6.3 思考过程可视化

系统支持展示模型的「思考过程」（reasoning）——模型在给出最终回答前的推理链路。前端通过可折叠面板呈现，帮助用户理解模型的推理逻辑，增强回答的可解释性。

### 6.4 中英文混合分块优化

文本分块器针对中英文混合文档定制了分隔符优先级，兼顾中文标点（。！？；，）和英文标点（. ! ? ; ,），确保在混合语言场景下的分块质量。

### 6.5 多知识库联合检索

支持在单次对话中同时关联多个知识库，系统将跨知识库进行联合语义检索，适用于需要综合多个文档来源的复杂问答场景。

### 6.6 流式响应体验

采用 SSE（Server-Sent Events）实现流式输出，模型每生成一个 token 即推送到前端渲染，首字符延迟低，用户无需等待完整回答生成即可开始阅读。

### 6.7 一键打包部署

系统支持将前后端打包为单一 macOS .dmg 安装包，用户双击安装后即可使用：
- **后端打包**：使用 PyInstaller 将 Python FastAPI 后端及全部依赖（ChromaDB、PyMuPDF 等）打包为独立可执行文件，嵌入 Electron 应用的 Resources 目录
- **动态端口分配**：Electron 主进程启动时自动寻找可用端口，避免端口冲突
- **进程生命周期管理**：应用启动时自动拉起后端进程并轮询 `/health` 确认就绪；退出时先发 SIGTERM 优雅关闭，5 秒超时后 SIGKILL 强制终止
- **环境自适应配置**：通过 `model_validator` 动态计算数据目录——打包模式使用 `~/Library/Application Support/Atlas/data/`，开发模式使用项目根目录下的 `data/`
- **开发体验不受影响**：所有打包相关逻辑通过 `app.isPackaged` 条件判断，开发模式完全保持原有行为

### 6.8 大文件向量化分批处理

对大文档产生的数百个文本片段，自动按每批 50 个分批发送给 Ollama Embedding 模型进行向量化，避免单次请求量过大导致超时或内存溢出。

---

## 七、系统运行环境

### 7.1 硬件要求

| 项目 | 最低要求 | 推荐配置 |
|------|---------|---------|
| CPU | 4 核 | 8 核以上 |
| 内存 | 16 GB | 32 GB |
| 显存 | 8 GB (用于 GPU 推理) | 16 GB 以上 |
| 磁盘 | 20 GB 可用空间 | SSD 50 GB 以上 |

> 注：如仅使用 CPU 推理，无显卡要求，但推理速度较慢。

### 7.2 软件环境

| 软件 | 版本要求 |
|------|---------|
| 操作系统 | Windows 10+、macOS 12+、Linux |
| Node.js | ≥ 18.0 |
| Python | ≥ 3.9 |
| Ollama | 最新版 |

### 7.3 模型要求

| 模型 | 用途 | 参数量 | 磁盘占用 |
|------|------|-------|---------|
| qwen3:14b | 对话生成 | 14B | ~8 GB |
| qwen3-embedding:4b | 文本向量化 | 4B | ~2.5 GB |

---

## 八、项目目录结构总览

```
Atlas/
├── frontend/                     # 前端工程（Electron + React）
│   ├── src/
│   │   ├── main/index.js         # Electron 主进程入口（含后端进程管理）
│   │   ├── preload/preload.js    # 预加载安全桥接脚本（含后端端口传递）
│   │   └── renderer/             # React 渲染进程
│   │       ├── App.tsx           # 根组件
│   │       ├── main.tsx          # React 入口
│   │       ├── components/       # UI 组件（ChatPanel, Sidebar, KnowledgeBaseView）
│   │       ├── services/api.ts   # API 服务层（动态 API 地址）
│   │       ├── stores/           # Zustand 状态管理
│   │       ├── types/electron.d.ts # Electron API 类型声明
│   │       └── styles/           # CSS 样式
│   ├── build/
│   │   └── entitlements.mac.plist # macOS 权限声明（网络、JIT、动态库加载）
│   ├── index.html                # HTML 模板
│   ├── package.json              # 依赖与脚本配置（含 electron-builder 打包配置）
│   ├── tsconfig.json             # TypeScript 配置
│   └── vite.config.ts            # Vite 构建配置
│
├── backend/                      # 后端工程（Python FastAPI）
│   ├── app/
│   │   ├── main.py               # FastAPI 应用入口
│   │   ├── config.py             # 全局配置（支持环境变量覆盖、打包模式自适应）
│   │   ├── api/                  # REST API 路由（chat, documents, knowledge_bases, history）
│   │   ├── core/                 # 核心逻辑（rag, vectorstore, ollama, parser, chunker）
│   │   ├── models/models.py      # SQLAlchemy ORM 模型
│   │   └── db/                   # 数据库（engine, session, CRUD）
│   ├── run.py                    # PyInstaller 入口脚本
│   ├── atlas-backend.spec        # PyInstaller 打包配置
│   └── requirements.txt          # Python 依赖
│
├── data/                         # 运行时数据（自动生成）
│   ├── chroma/                   # ChromaDB 向量库持久化
│   ├── sqlite/atlas.db           # SQLite 关系数据库
│   └── uploads/                  # 用户上传的文档文件
│
├── build.sh                      # 一键构建脚本（PyInstaller → Vite → electron-builder）
├── TODO.md                       # 待办事项
└── README.md                     # 项目说明
```

---

## 九、API 接口汇总

### 9.1 知识库管理

| 方法 | 路径 | 说明 |
|------|------|------|
| POST | `/api/knowledge-bases` | 创建知识库 |
| GET | `/api/knowledge-bases` | 获取知识库列表 |
| GET | `/api/knowledge-bases/{id}` | 获取知识库详情（含文档列表） |
| PUT | `/api/knowledge-bases/{id}` | 更新知识库信息 |
| DELETE | `/api/knowledge-bases/{id}` | 删除知识库（级联删除文档和向量） |

### 9.2 文档管理

| 方法 | 路径 | 说明 |
|------|------|------|
| POST | `/api/documents/upload` | 上传并索引文档 |
| GET | `/api/documents` | 获取文档列表（支持按知识库过滤） |
| GET | `/api/documents/{id}` | 获取文档详情（含分片内容） |
| DELETE | `/api/documents/{id}` | 删除文档（同时清理向量和文件） |

### 9.3 对话管理

| 方法 | 路径 | 说明 |
|------|------|------|
| POST | `/api/chat` | 发送消息（SSE 流式响应） |
| POST | `/api/chat/conversations` | 创建新对话 |
| GET | `/api/chat/conversations` | 获取对话列表 |
| GET | `/api/chat/conversations/{id}` | 获取对话详情（含消息记录） |
| PUT | `/api/chat/conversations/{id}` | 更新对话标题 |
| DELETE | `/api/chat/conversations/{id}` | 删除对话 |
| GET | `/api/chat/models` | 获取可用模型列表 |

### 9.4 历史记录

| 方法 | 路径 | 说明 |
|------|------|------|
| GET | `/api/history/messages/{conversation_id}` | 获取对话消息历史 |

---

## 十、总结

本项目设计并实现了 Atlas —— 一个基于 RAG 技术的本地知识库智能问答系统。系统采用 Electron + React 构建跨平台桌面客户端，Python FastAPI 提供后端 API 服务，Ollama 驱动本地大模型推理，ChromaDB 实现语义向量检索，SQLite 管理结构化数据。

系统完整实现了从文档上传、解析、分块、向量化索引，到语义检索、上下文注入、流式生成回答的全链路 RAG 流程。通过完全本地化的部署方式，在保证数据隐私的同时，提供了流畅的对话交互体验。同时，系统支持一键打包为 macOS .dmg 安装包（使用 PyInstaller 打包后端、electron-builder 打包前端），用户双击安装即可使用，无需手动配置开发环境。

项目代码结构清晰、模块化程度高，核心组件（文档解析器、向量数据库、LLM 服务）均采用接口抽象，具有良好的可扩展性，为后续替换模型、扩展文档格式、优化检索策略提供了便利的扩展基础。
